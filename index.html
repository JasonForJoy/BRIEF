<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <style>
        .content {
            font-size: 22px; /* Adjust the font size as desired */
        }
    </style>

    <style type="text/css">svg:not(:root).svg-inline--fa {
        overflow: visible
    }

    .svg-inline--fa {
        display: inline-block;
        font-size: inherit;
        height: 1em;
        overflow: visible;
        vertical-align: -.125em
    }

    .svg-inline--fa.fa-lg {
        vertical-align: -.225em
    }

    .svg-inline--fa.fa-w-1 {
        width: .0625em
    }

    .svg-inline--fa.fa-w-2 {
        width: .125em
    }

    .svg-inline--fa.fa-w-3 {
        width: .1875em
    }

    .svg-inline--fa.fa-w-4 {
        width: .25em
    }

    .svg-inline--fa.fa-w-5 {
        width: .3125em
    }

    .svg-inline--fa.fa-w-6 {
        width: .375em
    }

    .svg-inline--fa.fa-w-7 {
        width: .4375em
    }

    .svg-inline--fa.fa-w-8 {
        width: .5em
    }

    .svg-inline--fa.fa-w-9 {
        width: .5625em
    }

    .svg-inline--fa.fa-w-10 {
        width: .625em
    }

    .svg-inline--fa.fa-w-11 {
        width: .6875em
    }

    .svg-inline--fa.fa-w-12 {
        width: .75em
    }

    .svg-inline--fa.fa-w-13 {
        width: .8125em
    }

    .svg-inline--fa.fa-w-14 {
        width: .875em
    }

    .svg-inline--fa.fa-w-15 {
        width: .9375em
    }

    .svg-inline--fa.fa-w-16 {
        width: 1em
    }

    .svg-inline--fa.fa-w-17 {
        width: 1.0625em
    }

    .svg-inline--fa.fa-w-18 {
        width: 1.125em
    }

    .svg-inline--fa.fa-w-19 {
        width: 1.1875em
    }

    .svg-inline--fa.fa-w-20 {
        width: 1.25em
    }

    .svg-inline--fa.fa-pull-left {
        margin-right: .3em;
        width: auto
    }

    .svg-inline--fa.fa-pull-right {
        margin-left: .3em;
        width: auto
    }

    .svg-inline--fa.fa-border {
        height: 1.5em
    }

    .svg-inline--fa.fa-li {
        width: 2em
    }

    .svg-inline--fa.fa-fw {
        width: 1.25em
    }

    .fa-layers svg.svg-inline--fa {
        bottom: 0;
        left: 0;
        margin: auto;
        position: absolute;
        right: 0;
        top: 0
    }

    .fa-layers {
        display: inline-block;
        height: 1em;
        position: relative;
        text-align: center;
        vertical-align: -.125em;
        width: 1em
    }

    .fa-layers svg.svg-inline--fa {
        -webkit-transform-origin: center center;
        transform-origin: center center
    }

    .fa-layers-counter, .fa-layers-text {
        display: inline-block;
        position: absolute;
        text-align: center
    }

    .fa-layers-text {
        left: 50%;
        top: 50%;
        -webkit-transform: translate(-50%, -50%);
        transform: translate(-50%, -50%);
        -webkit-transform-origin: center center;
        transform-origin: center center
    }

    .fa-layers-counter {
        background-color: #ff253a;
        border-radius: 1em;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        color: #fff;
        height: 1.5em;
        line-height: 1;
        max-width: 5em;
        min-width: 1.5em;
        overflow: hidden;
        padding: .25em;
        right: 0;
        text-overflow: ellipsis;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top right;
        transform-origin: top right
    }

    .fa-layers-bottom-right {
        bottom: 0;
        right: 0;
        top: auto;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: bottom right;
        transform-origin: bottom right
    }

    .fa-layers-bottom-left {
        bottom: 0;
        left: 0;
        right: auto;
        top: auto;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: bottom left;
        transform-origin: bottom left
    }

    .fa-layers-top-right {
        right: 0;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top right;
        transform-origin: top right
    }

    .fa-layers-top-left {
        left: 0;
        right: auto;
        top: 0;
        -webkit-transform: scale(.25);
        transform: scale(.25);
        -webkit-transform-origin: top left;
        transform-origin: top left
    }

    .fa-lg {
        font-size: 1.3333333333em;
        line-height: .75em;
        vertical-align: -.0667em
    }

    .fa-xs {
        font-size: .75em
    }

    .fa-sm {
        font-size: .875em
    }

    .fa-1x {
        font-size: 1em
    }

    .fa-2x {
        font-size: 2em
    }

    .fa-3x {
        font-size: 3em
    }

    .fa-4x {
        font-size: 4em
    }

    .fa-5x {
        font-size: 5em
    }

    .fa-6x {
        font-size: 6em
    }

    .fa-7x {
        font-size: 7em
    }

    .fa-8x {
        font-size: 8em
    }

    .fa-9x {
        font-size: 9em
    }

    .fa-10x {
        font-size: 10em
    }

    .fa-fw {
        text-align: center;
        width: 1.25em
    }

    .fa-ul {
        list-style-type: none;
        margin-left: 2.5em;
        padding-left: 0
    }

    .fa-ul > li {
        position: relative
    }

    .fa-li {
        left: -2em;
        position: absolute;
        text-align: center;
        width: 2em;
        line-height: inherit
    }

    .fa-border {
        border: solid .08em #eee;
        border-radius: .1em;
        padding: .2em .25em .15em
    }

    .fa-pull-left {
        float: left
    }

    .fa-pull-right {
        float: right
    }

    .fa.fa-pull-left, .fab.fa-pull-left, .fal.fa-pull-left, .far.fa-pull-left, .fas.fa-pull-left {
        margin-right: .3em
    }

    .fa.fa-pull-right, .fab.fa-pull-right, .fal.fa-pull-right, .far.fa-pull-right, .fas.fa-pull-right {
        margin-left: .3em
    }

    .fa-spin {
        -webkit-animation: fa-spin 2s infinite linear;
        animation: fa-spin 2s infinite linear
    }

    .fa-pulse {
        -webkit-animation: fa-spin 1s infinite steps(8);
        animation: fa-spin 1s infinite steps(8)
    }

    @-webkit-keyframes fa-spin {
        0% {
            -webkit-transform: rotate(0);
            transform: rotate(0)
        }
        100% {
            -webkit-transform: rotate(360deg);
            transform: rotate(360deg)
        }
    }

    @keyframes fa-spin {
        0% {
            -webkit-transform: rotate(0);
            transform: rotate(0)
        }
        100% {
            -webkit-transform: rotate(360deg);
            transform: rotate(360deg)
        }
    }

    .fa-rotate-90 {
        -webkit-transform: rotate(90deg);
        transform: rotate(90deg)
    }

    .fa-rotate-180 {
        -webkit-transform: rotate(180deg);
        transform: rotate(180deg)
    }

    .fa-rotate-270 {
        -webkit-transform: rotate(270deg);
        transform: rotate(270deg)
    }

    .fa-flip-horizontal {
        -webkit-transform: scale(-1, 1);
        transform: scale(-1, 1)
    }

    .fa-flip-vertical {
        -webkit-transform: scale(1, -1);
        transform: scale(1, -1)
    }

    .fa-flip-both, .fa-flip-horizontal.fa-flip-vertical {
        -webkit-transform: scale(-1, -1);
        transform: scale(-1, -1)
    }

    :root .fa-flip-both, :root .fa-flip-horizontal, :root .fa-flip-vertical, :root .fa-rotate-180, :root .fa-rotate-270, :root .fa-rotate-90 {
        -webkit-filter: none;
        filter: none
    }

    .fa-stack {
        display: inline-block;
        height: 2em;
        position: relative;
        width: 2.5em
    }

    .fa-stack-1x, .fa-stack-2x {
        bottom: 0;
        left: 0;
        margin: auto;
        position: absolute;
        right: 0;
        top: 0
    }

    .svg-inline--fa.fa-stack-1x {
        height: 1em;
        width: 1.25em
    }

    .svg-inline--fa.fa-stack-2x {
        height: 2em;
        width: 2.5em
    }

    .fa-inverse {
        color: #fff
    }

    .sr-only {
        border: 0;
        clip: rect(0, 0, 0, 0);
        height: 1px;
        margin: -1px;
        overflow: hidden;
        padding: 0;
        position: absolute;
        width: 1px
    }

    .sr-only-focusable:active, .sr-only-focusable:focus {
        clip: auto;
        height: auto;
        margin: 0;
        overflow: visible;
        position: static;
        width: auto
    }

    .svg-inline--fa .fa-primary {
        fill: var(--fa-primary-color, currentColor);
        opacity: 1;
        opacity: var(--fa-primary-opacity, 1)
    }

    .svg-inline--fa .fa-secondary {
        fill: var(--fa-secondary-color, currentColor);
        opacity: .4;
        opacity: var(--fa-secondary-opacity, .4)
    }

    .svg-inline--fa.fa-swap-opacity .fa-primary {
        opacity: .4;
        opacity: var(--fa-secondary-opacity, .4)
    }

    .svg-inline--fa.fa-swap-opacity .fa-secondary {
        opacity: 1;
        opacity: var(--fa-primary-opacity, 1)
    }

    .svg-inline--fa mask .fa-primary, .svg-inline--fa mask .fa-secondary {
        fill: #000
    }

    .fad.fa-inverse {
        color: #fff
    }</style>
    <link rel="stylesheet" href="src/codemirror.min.css">
    <script src="src/runmode-standalone.min.js"></script>
    <script src="src/python.min.js"></script>

    <title>BRIEF</title>


    <!-- Google tag (gtag.js)
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S3G8BGY5W5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-S3G8BGY5W5');
    </script>
    -->
    
    <link href="src/css" rel="stylesheet">

    <link rel="stylesheet" href="src/bulma.min.css">
    <link rel="stylesheet" href="src/bulma-carousel.min.css">
    <link rel="stylesheet" href="src/bulma-slider.min.css">
    <link rel="stylesheet" href="src/fontawesome.all.min.css">
    <link rel="stylesheet" href="src/academicons.min.css">
    <link rel="stylesheet" href="src/index.css">
    <link rel="icon" href="src/pluslab.png">

    <script src="src/jquery.min.js"></script>
    <script defer="" src="src/fontawesome.all.min.js"></script>
    <script src="src/bulma-carousel.min.js"></script>
    <script src="src/bulma-slider.min.js"></script>
    <script src="src/index.js"></script>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://JasonForJoy.github.io/BRIEF/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://jasonforjoy.github.io/Model-Editing-Hurt/">
            Model-Editing
          </a>
          <a class="navbar-item" href="https://mragbench.github.io/">
            MRAG-Bench
          </a>
          <a class="navbar-item" href="https://xiaowu0162.github.io/syncheck/">
            SynCheck
          </a>
        </div>
      </div>
    </div>

  </div>
  </nav>
    
<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        </h1>
                    <h2 class="subtitle is-3 publication-subtitle" >
                        <b>BRIEF: Bridging Retrieval and Inference for Multi-hop Reasoning via Compression</b></h2>
                    <!-- <h3><strong>Accepted by EMNLP 2024 (Main Track)</strong>🎉</h3> -->
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <a href="https://lieziwind.github.io/">Yuankai Li</a><sup>1&#42;</sup>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://jasonforjoy.github.io/">Jia-Chen Gu</a><sup>2&#42;</sup>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://xiaowu0162.github.io/">Di Wu</a><sup>2</sup>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://web.cs.ucla.edu/~kwchang/">Kai-Wei Chang</a><sup>2</sup>,&nbsp;
                        </span>
                        <span class="author-block">
                            <a href="https://violetpeng.github.io/">Nanyun Peng</a><sup>2</sup>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <sup>1</sup><span class="author-block">Fudan University</span> &nbsp;
                        <sup>2</sup><span class="author-block">University of California, Los Angeles</span>
                        <h3>&#42;Equal contribution</h3>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            
                            <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            
                            
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/JasonForJoy/BRIEF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false"
                           data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg"
                           viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor"
                                                                        d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
                      <!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!-- Model Link. -->


                            <!-- Twitter Link -->
              <span class="link-block">
                <a href="https://x.com/Jiachen_Gu/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">🌐</p>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>


                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="content has-text-justified">
              <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
                Abstract
              </h2>
                <p>
                Retrieval-augmented generation (RAG) can supplement large language models (LLMs) by integrating external knowledge. However, as the number of retrieved documents increases, the input length to LLMs grows linearly, causing a dramatic increase in latency and a degradation in long-context understanding. This is particularly serious for multi-hop questions that require a chain of reasoning across documents. To accelerate inference, reduce costs, and minimize distractions, this paper presents BRIEF (<b><span class="dnerf">B</span></b>ridging <b><span class="dnerf">R</span></b>etrieval and <b><span class="dnerf">I</span></b>nference through <b><span class="dnerf">E</span></b>vidence <b><span class="dnerf">F</span></b>usion), a lightweight approach that performs query-aware multi-hop reasoning by compressing retrieved documents into highly dense textual summaries to integrate into in-context learning. To enable learning compression for multi-hop reasoning, we curate synthetic data by extracting atomic proposition expressions that encapsulate distinct factoids from the source documents to compose synthetic summaries. Based on our synthetic data built entirely by open-source models, BRIEF generates more concise summaries and enables a range of LLMs to achieve exceptional open-domain question answering (QA) performance. For example, on HotpotQA, BRIEF improves the compression rate by 2 times compared to the state-of-the-art baseline, while outperforming it by 3.00% EM and 4.16% F1 with Flan-UL2 as the reader LM. It also generates more concise summaries than proprietary GPT-3.5, while demonstrating nearly identical QA performance.
                </p>
            <br>            
        </div>
      </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            The BRIEF Compressor
          </h2>
          <div class="content has-text-justified">
            <p>
                BRIEF is a lightweight, T5-based approach that performs query-aware multi-hop reasoning by compressing retrieved documents into highly dense textual summaries to integrate into in-context learning.
            </p>
            <p>
                Unlike conventional methods that focus on compression for single-hop questions (Xu et al., 2024a; Cao et al., 2024), BRIEF is specifically trained to summarize the most pertinent knowledge from multiple documents that is essential for answering multi-hop questions. 
            </p>
            <p>
                Compare to token-, phrase-, or sentence-level compression (Jiang et al., 2023; Li et al., 2023), the summaries produced by BRIEF organize and synthesize evidence relevant to the query in a more concise and natural language format, making them more effective for use by the follow-up reader LM.
            </p>
            <img src="src/BRIEF_inference.png" class="center", style="width: 100%; display: block; margin: auto;">
          </div>
    </div>
      <!--/ Abstract. -->
    </section>

<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Synthetic Data
          </h2>
          <div class="content has-text-justified">
            <p>
                Unlike state-of-the-art fine-tuned compressor distilled from extreme-scale proprietary LLMs (Xu et al., 2024a), BRIEF is trained on <b><em>synthetic data</em></b> through a pipeline built entirely by <b><em>open-source models</em></b>, without relying on any proprietary LLMs and human annotations.
            </p>
            <img src="src/BRIEF_train.png" class="center", style="width: 100%; display: block; margin: auto;">
            &nbsp;
            <p>
                <ul>
                    <li>The synthetic data pipeline extracts atomic proposition expressions that encapsulate distinct factoids from the source documents to compose synthetic summaries.</li>
                    <li>The pipeline designs an automatic validation mechanism to filter out spurious multi-hop questions and corresponding summaries, ensuring that only those requiring genuine multi-hop reasoning are retained, ultimately improving the quality and reliability of the synthetic data. </li>
                    <li>Besides, the synthetic data exhibits an impressive awareness of multi-hop reasoning and potential to scale up, offering a data-centric approach to constructing high-quality and cost-effective synthetic data for context compression.</li>
                </ul>
            </p>
          </div>
    </div>
    </section>

<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Experimental Results
          </h2>
          <div class="content has-text-justified">
            <p>
                We evaluated on the following datasets: <b><em>HotpotQA</em></b> (Yang et al., 2018), <b><em>MuSiQue</em></b> (Trivedi et al., 2022), <b><em>Natural Questions (NQ)</em></b> (Kwiatkowski et al., 2019), and <b><em>TriviaQA</em></b> (Joshi et al., 2017). Notably, the first two datasets primarily consist of multi-hop questions, whereas the latter two are mainly composed of single-hop questions. Especially for TriviaQA and NQ, we have curated high-quality <b><em>multi-hop versions</em></b> using our proposed synthetic data pipeline, named <b><em>MultiHop-TriviaQA</em></b> and <b><em>MultiHop-NQ</em></b>. We contribute high-quality multi-hop test sets that reveal the limitations of previous compressors, which perform well in single-hop but fall behind our method in multi-hop settings.
            </p>
            <img src="src/result_multihop.png" class="center", style="width: 100%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>RIEF achieves a compression rate of 19.19x, with only a 1.60-point decrease in EM and a 1.83-point decrease in F1 compared to <b><em>prepending full documents</em></b> on HotpotQA. </li>
                    <li>Compared to <b><em>RECOMP</em></b>, BRIEF compresses by higher 19.19x than its 10.02x, while still outperforming it by 3.00-point EM and 4.16-point F1 on HotpotQA. On MultiHop-NQ, we observed a similar trend, with BRIEF’s higher 16.85x than RECOMP’s 10.84x, while outperforming RECOMP by 3.78-point EM and 4.39-point F1. </li>
                    <li>Compared to the <b><em>proprietary LLM GPT-3.5</em></b>, BRIEF achieves higher compression rates while delivering competitive QA performance. Take the results on HotpotQA as an example, GPT-3.5 achieves a compression rate of 14.77x, and QA performance of 31.60% EM and 42.65% F1. While BRIEF achieves higher 19.19x and can still deliver nearly similar QA results of 31.20% EM and 42.07% F1 performance.</li>
                </ul>
            </p>

            <img src="src/result_singlehop.png" class="center", style="width: 50%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>BRIEF achieves a compression rate of 29.76x, with only a 2.55-point decrease in EM and a 3.49-point decrease in F1 compared to <b><em>prepending full documents</em></b> on TriviaQA. On NQ, we observed a similar trend, with a compression rate of 17.67x, resulting in only a 2.99-point decrease in EM and a 3.28-point decrease in F1. </li>
                    <li>Compared to <b><em>RECOMP</em></b>, BRIEF compresses by higher 29.76x than its 16.23x, while still outperforming RECOMP on TriviaQA. </li>
                    <li>Com-pared to <b><em>GPT-3.5</em></b>, BRIEF achieves competitive QA performance, while its compression rate of 17.67x significantly outperforms GPT-3.5’s 11.33x.</li>
                </ul>
            </p>
          </div>
    </div>
    </section>

<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Analysis
          </h2>
          <div class="content has-text-justified">
            <b><em>The transfer ability of compressed summaries across LMs</em></b>
            <img src="src/analysis_transfer.png" class="center", style="width: 50%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>This ability involves evaluating how well a compressed summary can maintain the core semantics relevant to the query, while also using an expression format that is compatible with a wider range of LMs. We selected models from the same family to avoid model selection bias. </li>
                    <li>Since our compression takes the form of propositions, it is more interpretable and transfers better across LMs compared to RECOMP and GPT-3.5. </li>
                    <li>In comparison to RECOMP and GPT-3.5, the performance of BRIEF drops more slightly when transferring from Phi-3-mini to Phi-3-small, and enlarges more from Phi-3-small to Phi-3-medium. These results implied the robustness and consistency of the compressed summaries generated by BRIEF.</li>
                </ul>
            </p>

            <b><em>The sensitivity of summary length to multi-hop nature of questions</em></b>
            <img src="src/analysis_length.png" class="center", style="width: 50%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>The variation in summary length regarding question complexity can, to some extent, reflect the compressor’s sensitivity to that complexity. </li>
                    <li>As there is no established ground truth for the length of compressed summaries for each question, the results from GPT-3.5 were used as the reference oracle. </li>
                    <li>The results indicate that BRIEF consistently aligns with GPT-3.5 in terms of the sensitivity to the multi-hop nature of questions while generating more concise summaries. This alignment suggests that BRIEF effectively understands the complexity of questions and adaptively collects the necessary evidence based on specific demands to formulate a complete and accurate summary for answering this question.</li>
                </ul>
            </p>

            <b><em>The improvement of latency in terms of the over-all computational overhead </em></b>
            <img src="src/analysis_flops.png" class="center", style="width: 50%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>When employing BRIEF for compression, the number of GFLOPs required to process the compressed documents is significantly reduced compared to the amount required when using Flan-UL2 alone on the original, uncompressed set of top-5 documents. The total amount of computation is reduced to less than 30% of what it was before compression. </li>
                    <li>This reduction in GFLOPs highlights BRIEF’s potential to optimize inference, especially for large-scale document retrieval and processing, by enabling the LM to focus on compressed, more relevant infor-mation while maintaining comparable accuracy.</li>
                </ul>
            </p>

            <b><em>The scalability to compress longer documents</em></b>
            <img src="src/analysis_scale.png" class="center", style="width: 50%; display: block; margin: auto;">
            <p>
                <ul>
                    <li>We further explored whether the proposed compressors could be effectively applied to more complex scenarios, particularly those involving documents whose lengths are an order of magnitude longer. A preliminary study was conducted by expanding the scope of retrieved documents from the top-5 to the top-25.  </li>
                    <li>To avoid document position bias, these documents were shuffled and uniformly divided into document chunks, each containing five documents. Each chunk was then compressed using the trained compressor according to standard procedures. Finally, the compressed results of each chunk were concatenated to produce the overall compressed summary. </li>
                    <li>BRIEF demonstrates better scalability in scenarios where the document length is significantly longer. BRIEF is relatively stable, while RECOMP shows significant performance degradation. This result suggests that RECOMP has a limited ability to identify relevant evidence within a longer context containing more distracting information. Overall, our findings suggest that BRIEF has the potential to be extended but still requires further investigation for compressing longer contexts, which will be explored in future.</li>
                </ul>
            </p>
          </div>
    </div>
    </section>

<section class="section">
    <div class="container is-max-desktop">
          <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Takeaways
          </h2>
          <div class="content has-text-justified">
            <p>
                <ul>
                    <li>This study pioneers the exploration of long-context reasoning and compression of RAG for multi-hop questions. </li>
                    <li>A synthetic data pipeline, built entirely by open-source models, is designed to enhance the awareness of multi-hop reasoning and shows promise to scale up due to its low cost.</li>
                    <li>BRIEF, trained on a curated dataset, achieves exceptional QA performance with more concise summaries compared to proprietary LLM-based compressors. </li>
                    <li>We contribute high-quality multi-hop test sets that reveal the limitations of previous compressors, which perform well in single-hop but fall behind our method in multi-hop settings.</li>
                </ul>
            </p>
          </div>
    </div>
    </section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop" content> 
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{li-etal-2024-brief,
 title = "BRIEF: Bridging Retrieval and Inference for Multi-hop Reasoning via Compression",
 author = "Li, Yuankai  and
           Gu, Jia-Chen  and
           Wu, Di  and
           Chang, Kai-Wei  and
           Peng, Nanyun",
 year = "2024"
}</code></pre>
</div>
  </section>
 

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p style="color:gray;font-size:9.9px;">
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
 

</body>
</html>
